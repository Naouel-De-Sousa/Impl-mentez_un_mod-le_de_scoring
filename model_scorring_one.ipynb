{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b0efd17-b5a2-4c4a-ab27-2a3026d82b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.3.0-py3-none-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\naoue\\anaconda3\\envs\\mon_env\\lib\\site-packages (from lightgbm) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\naoue\\anaconda3\\envs\\mon_env\\lib\\site-packages (from lightgbm) (1.10.1)\n",
      "Downloading lightgbm-4.3.0-py3-none-win_amd64.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.2/1.3 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.3/1.3 MB 14.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 12.2 MB/s eta 0:00:00\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7bb43727-95aa-46e5-a181-bb9acb39d8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08053e0-cff0-45f0-ae7e-80404867e2e5",
   "metadata": {},
   "source": [
    "# Les données"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4b64648a-1ce0-4247-8782-27da9ddb49c4",
   "metadata": {},
   "source": [
    "# Lecture des fichiers et réduction de la mémoire utilisée\n",
    "\n",
    "X_train = pd.read_csv('application_train.csv')\n",
    "\n",
    "X_test = pd.read_csv('application_test.csv')\n",
    "\n",
    "bureau = pd.read_csv('bureau.csv')\n",
    "\n",
    "bureau_balance = pd.read_csv('bureau_balance.csv')\n",
    "\n",
    "pos_cash = pd.read_csv('POS_CASH_balance.csv')\n",
    "\n",
    "credit_card = pd.read_csv('credit_card_balance.csv')\n",
    "\n",
    "previous_application = pd.read_csv('previous_application.csv')\n",
    "\n",
    "installments_payments = pd.read_csv('installments_payments.csv')\n",
    "\n",
    "columns_description = pd.read_csv('HomeCredit_columns_description.csv')\n",
    "\n",
    "sample_submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3f158301-917f-4039-af18-5b75cc80d483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ac9ef66a-5699-4e7b-9737-f4c3e6ddd786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding for categorical columns with get_dummies\n",
    "def one_hot_encoder(df, nan_as_category = True):\n",
    "    original_columns = list(df.columns)\n",
    "    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    df = pd.get_dummies(df, columns= categorical_columns, dummy_na= nan_as_category)\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "939fc9f2-2c7f-4682-be1b-5b0706d78bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess application_train.csv and application_test.csv\n",
    "def application_train_test(num_rows = None, nan_as_category = False):\n",
    "    # Read data and merge\n",
    "    df = pd.read_csv('application_train.csv', nrows= num_rows)\n",
    "    test_df = pd.read_csv('application_test.csv', nrows= num_rows)\n",
    "    print(\"Train samples: {}, test samples: {}\".format(len(df), len(test_df)))\n",
    "    df = pd.concat([df, test_df], ignore_index=True)\n",
    "    # Optional: Remove 4 applications with XNA CODE_GENDER (train set)\n",
    "    df = df[df['CODE_GENDER'] != 'XNA']\n",
    "    \n",
    "    # Categorical features with Binary encode (0 or 1; two categories)\n",
    "    for bin_feature in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n",
    "        df[bin_feature], uniques = pd.factorize(df[bin_feature])\n",
    "    # Categorical features with One-Hot encode\n",
    "    df, cat_cols = one_hot_encoder(df, nan_as_category)\n",
    "    \n",
    "    # NaN values for DAYS_EMPLOYED: 365.243 -> nan\n",
    "    df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\n",
    "    # Some simple new features (percentages)\n",
    "    df['DAYS_EMPLOYED_PERC'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "    df['INCOME_CREDIT_PERC'] = df['AMT_INCOME_TOTAL'] / df['AMT_CREDIT']\n",
    "    df['INCOME_PER_PERSON'] = df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS']\n",
    "    df['ANNUITY_INCOME_PERC'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "    df['PAYMENT_RATE'] = df['AMT_ANNUITY'] / df['AMT_CREDIT']\n",
    "    del test_df\n",
    "    gc.collect()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dea65604-4ec9-4f8d-a88d-8013f666ebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess bureau.csv and bureau_balance.csv\n",
    "def bureau_and_balance(num_rows = None, nan_as_category = True):\n",
    "    bureau = pd.read_csv('bureau.csv', nrows = num_rows)\n",
    "    bb = pd.read_csv('bureau_balance.csv', nrows = num_rows)\n",
    "    bb, bb_cat = one_hot_encoder(bb, nan_as_category)\n",
    "    bureau, bureau_cat = one_hot_encoder(bureau, nan_as_category)\n",
    "    \n",
    "    # Bureau balance: Perform aggregations and merge with bureau.csv\n",
    "    bb_aggregations = {'MONTHS_BALANCE': ['min', 'max', 'size']}\n",
    "    for col in bb_cat:\n",
    "        bb_aggregations[col] = ['mean']\n",
    "    bb_agg = bb.groupby('SK_ID_BUREAU').agg(bb_aggregations)\n",
    "    bb_agg.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in bb_agg.columns.tolist()])\n",
    "    bureau = bureau.join(bb_agg, how='left', on='SK_ID_BUREAU')\n",
    "    bureau.drop(['SK_ID_BUREAU'], axis=1, inplace= True)\n",
    "    del bb, bb_agg\n",
    "    gc.collect()\n",
    "    \n",
    "    # Bureau and bureau_balance numeric features\n",
    "    num_aggregations = {\n",
    "        'DAYS_CREDIT': ['min', 'max', 'mean', 'var'],\n",
    "        'DAYS_CREDIT_ENDDATE': ['min', 'max', 'mean'],\n",
    "        'DAYS_CREDIT_UPDATE': ['mean'],\n",
    "        'CREDIT_DAY_OVERDUE': ['max', 'mean'],\n",
    "        'AMT_CREDIT_MAX_OVERDUE': ['mean'],\n",
    "        'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
    "        'AMT_CREDIT_SUM_LIMIT': ['mean', 'sum'],\n",
    "        'AMT_ANNUITY': ['max', 'mean'],\n",
    "        'CNT_CREDIT_PROLONG': ['sum'],\n",
    "        'MONTHS_BALANCE_MIN': ['min'],\n",
    "        'MONTHS_BALANCE_MAX': ['max'],\n",
    "        'MONTHS_BALANCE_SIZE': ['mean', 'sum']\n",
    "    }\n",
    "    # Bureau and bureau_balance categorical features\n",
    "    cat_aggregations = {}\n",
    "    for cat in bureau_cat: cat_aggregations[cat] = ['mean']\n",
    "    for cat in bb_cat: cat_aggregations[cat + \"_MEAN\"] = ['mean']\n",
    "    \n",
    "    bureau_agg = bureau.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    bureau_agg.columns = pd.Index(['BURO_' + e[0] + \"_\" + e[1].upper() for e in bureau_agg.columns.tolist()])\n",
    "    # Bureau: Active credits - using only numerical aggregations\n",
    "    active = bureau[bureau['CREDIT_ACTIVE_Active'] == 1]\n",
    "    active_agg = active.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    active_agg.columns = pd.Index(['ACTIVE_' + e[0] + \"_\" + e[1].upper() for e in active_agg.columns.tolist()])\n",
    "    bureau_agg = bureau_agg.join(active_agg, how='left', on='SK_ID_CURR')\n",
    "    del active, active_agg\n",
    "    gc.collect()\n",
    "    # Bureau: Closed credits - using only numerical aggregations\n",
    "    closed = bureau[bureau['CREDIT_ACTIVE_Closed'] == 1]\n",
    "    closed_agg = closed.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    closed_agg.columns = pd.Index(['CLOSED_' + e[0] + \"_\" + e[1].upper() for e in closed_agg.columns.tolist()])\n",
    "    bureau_agg = bureau_agg.join(closed_agg, how='left', on='SK_ID_CURR')\n",
    "    del closed, closed_agg, bureau\n",
    "    gc.collect()\n",
    "    return bureau_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f61d614e-a131-47e4-874d-a0619550a066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def previous_applications(num_rows = None, nan_as_category = True):\n",
    "    prev = pd.read_csv('previous_application.csv', nrows = num_rows)\n",
    "    prev, cat_cols = one_hot_encoder(prev, nan_as_category= True)\n",
    "    # Days 365.243 values -> nan\n",
    "    prev['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)\n",
    "    # Add feature: value ask / value received percentage\n",
    "    prev['APP_CREDIT_PERC'] = prev['AMT_APPLICATION'] / prev['AMT_CREDIT']\n",
    "    # Previous applications numeric features\n",
    "    num_aggregations = {\n",
    "        'AMT_ANNUITY': ['min', 'max', 'mean'],\n",
    "        'AMT_APPLICATION': ['min', 'max', 'mean'],\n",
    "        'AMT_CREDIT': ['min', 'max', 'mean'],\n",
    "        'APP_CREDIT_PERC': ['min', 'max', 'mean', 'var'],\n",
    "        'AMT_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'AMT_GOODS_PRICE': ['min', 'max', 'mean'],\n",
    "        'HOUR_APPR_PROCESS_START': ['min', 'max', 'mean'],\n",
    "        'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "        'CNT_PAYMENT': ['mean', 'sum'],\n",
    "    }\n",
    "    # Previous applications categorical features\n",
    "    cat_aggregations = {}\n",
    "    for cat in cat_cols:\n",
    "        cat_aggregations[cat] = ['mean']\n",
    "    \n",
    "    prev_agg = prev.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    prev_agg.columns = pd.Index(['PREV_' + e[0] + \"_\" + e[1].upper() for e in prev_agg.columns.tolist()])\n",
    "    # Previous Applications: Approved Applications - only numerical features\n",
    "    approved = prev[prev['NAME_CONTRACT_STATUS_Approved'] == 1]\n",
    "    approved_agg = approved.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    approved_agg.columns = pd.Index(['APPROVED_' + e[0] + \"_\" + e[1].upper() for e in approved_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(approved_agg, how='left', on='SK_ID_CURR')\n",
    "    # Previous Applications: Refused Applications - only numerical features\n",
    "    refused = prev[prev['NAME_CONTRACT_STATUS_Refused'] == 1]\n",
    "    refused_agg = refused.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    refused_agg.columns = pd.Index(['REFUSED_' + e[0] + \"_\" + e[1].upper() for e in refused_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(refused_agg, how='left', on='SK_ID_CURR')\n",
    "    del refused, refused_agg, approved, approved_agg, prev\n",
    "    gc.collect()\n",
    "    return prev_agg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "51cc3e9b-9d51-4820-bd36-e4e94cbef8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess POS_CASH_balance.csv\n",
    "def pos_cash(num_rows = None, nan_as_category = True):\n",
    "    pos = pd.read_csv('POS_CASH_balance.csv', nrows = num_rows)\n",
    "    pos, cat_cols = one_hot_encoder(pos, nan_as_category= True)\n",
    "    # Features\n",
    "    aggregations = {\n",
    "        'MONTHS_BALANCE': ['max', 'mean', 'size'],\n",
    "        'SK_DPD': ['max', 'mean'],\n",
    "        'SK_DPD_DEF': ['max', 'mean']\n",
    "    }\n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = ['mean']\n",
    "    \n",
    "    pos_agg = pos.groupby('SK_ID_CURR').agg(aggregations)\n",
    "    pos_agg.columns = pd.Index(['POS_' + e[0] + \"_\" + e[1].upper() for e in pos_agg.columns.tolist()])\n",
    "    # Count pos cash accounts\n",
    "    pos_agg['POS_COUNT'] = pos.groupby('SK_ID_CURR').size()\n",
    "    del pos\n",
    "    gc.collect()\n",
    "    return pos_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "85882df7-ec2d-4f76-bbd1-42a7ea4d2d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def installments_payments(num_rows = None, nan_as_category = True):\n",
    "    ins = pd.read_csv('installments_payments.csv', nrows = num_rows)\n",
    "    ins, cat_cols = one_hot_encoder(ins, nan_as_category= True)\n",
    "    # Percentage and difference paid in each installment (amount paid and installment value)\n",
    "    ins['PAYMENT_PERC'] = ins['AMT_PAYMENT'] / ins['AMT_INSTALMENT']\n",
    "    ins['PAYMENT_DIFF'] = ins['AMT_INSTALMENT'] - ins['AMT_PAYMENT']\n",
    "    # Days past due and days before due (no negative values)\n",
    "    ins['DPD'] = ins['DAYS_ENTRY_PAYMENT'] - ins['DAYS_INSTALMENT']\n",
    "    ins['DBD'] = ins['DAYS_INSTALMENT'] - ins['DAYS_ENTRY_PAYMENT']\n",
    "    ins['DPD'] = ins['DPD'].apply(lambda x: x if x > 0 else 0)\n",
    "    ins['DBD'] = ins['DBD'].apply(lambda x: x if x > 0 else 0)\n",
    "    # Features: Perform aggregations\n",
    "    aggregations = {\n",
    "        'NUM_INSTALMENT_VERSION': ['nunique'],\n",
    "        'DPD': ['max', 'mean', 'sum'],\n",
    "        'DBD': ['max', 'mean', 'sum'],\n",
    "        'PAYMENT_PERC': ['max', 'mean', 'sum', 'var'],\n",
    "        'PAYMENT_DIFF': ['max', 'mean', 'sum', 'var'],\n",
    "        'AMT_INSTALMENT': ['max', 'mean', 'sum'],\n",
    "        'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n",
    "        'DAYS_ENTRY_PAYMENT': ['max', 'mean', 'sum']\n",
    "    }\n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = ['mean']\n",
    "    ins_agg = ins.groupby('SK_ID_CURR').agg(aggregations)\n",
    "    ins_agg.columns = pd.Index(['INSTAL_' + e[0] + \"_\" + e[1].upper() for e in ins_agg.columns.tolist()])\n",
    "    # Count installments accounts\n",
    "    ins_agg['INSTAL_COUNT'] = ins.groupby('SK_ID_CURR').size()\n",
    "    del ins\n",
    "    gc.collect()\n",
    "    return ins_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "be4bfab9-dc2e-475e-a7f7-1abb42cb1688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess credit_card_balance.csv\n",
    "def credit_card_balance(num_rows = None, nan_as_category = True):\n",
    "    cc = pd.read_csv('credit_card_balance.csv', nrows = num_rows)\n",
    "    cc, cat_cols = one_hot_encoder(cc, nan_as_category= True)\n",
    "    # General aggregations\n",
    "    cc.drop(['SK_ID_PREV'], axis= 1, inplace = True)\n",
    "    cc_agg = cc.groupby('SK_ID_CURR').agg(['min', 'max', 'mean', 'sum', 'var'])\n",
    "    cc_agg.columns = pd.Index(['CC_' + e[0] + \"_\" + e[1].upper() for e in cc_agg.columns.tolist()])\n",
    "    # Count credit card lines\n",
    "    cc_agg['CC_COUNT'] = cc.groupby('SK_ID_CURR').size()\n",
    "    del cc\n",
    "    gc.collect()\n",
    "    return cc_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "accad30d-71bf-4443-a71a-0c6e5b20a37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display/plot feature importance\n",
    "def display_importances(feature_importance_df_):\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('lgbm_importances01.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0b22327d-8077-4eaf-a6c0-a763640acb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def kfold_lightgbm_grid_search(df, num_folds, stratified=False, debug=False):\n",
    "    # Division en ensembles d'entraînement/validation et de test\n",
    "    train_df = df[df['TARGET'].notnull()]\n",
    "    test_df = df[df['TARGET'].isnull()]\n",
    "    print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n",
    "    \n",
    "    # Sélection des caractéristiques pour l'entraînement\n",
    "    feats = [f for f in train_df.columns if f not in ['TARGET', 'SK_ID_CURR', 'SK_ID_BUREAU', 'SK_ID_PREV', 'index']]\n",
    "    \n",
    "    # Paramètres pour GridSearchCV\n",
    "    param_grid = {\n",
    "        'n_estimators': [1000, 5000],\n",
    "        'learning_rate': [0.01, 0.02],\n",
    "        'num_leaves': [31, 34],\n",
    "        'colsample_bytree': [0.9497036],\n",
    "        'subsample': [0.8715623],\n",
    "        'max_depth': [7, 8],\n",
    "        'reg_alpha': [0.041545473],\n",
    "        'reg_lambda': [0.0735294],\n",
    "        'min_split_gain': [0.0222415],\n",
    "        'min_child_weight': [39.3259775]\n",
    "    }\n",
    "    \n",
    "    # Choix du type de KFold\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=1001)\n",
    "    else:\n",
    "        folds = KFold(n_splits=num_folds, shuffle=True, random_state=1001)\n",
    "\n",
    "    # Initialisation du classifieur LightGBM\n",
    "    estimator = LGBMClassifier(nthread=4, silent=-1, verbose=-1)\n",
    "    \n",
    "    # GridSearchCV\n",
    "    gsearch = GridSearchCV(estimator=estimator, param_grid=param_grid, scoring='roc_auc', n_jobs=-1, cv=folds, verbose=3)\n",
    "    \n",
    "    # Séparer les données en X et y\n",
    "    X_train = train_df[feats]\n",
    "    y_train = train_df['TARGET']\n",
    "    \n",
    "    # Lancer la recherche par grille\n",
    "    gsearch.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Meilleur score AUC: %s\" % gsearch.best_score_)\n",
    "    print(\"Meilleurs paramètres: %s\" % gsearch.best_params_)\n",
    "    \n",
    "    # Prédiction sur l'ensemble de test avec le meilleur modèle trouvé\n",
    "    test_df['TARGET'] = gsearch.predict_proba(test_df[feats])[:, 1]\n",
    "    \n",
    "    # Sauvegarder les prédictions si nécessaire\n",
    "    if not debug:\n",
    "        test_df[['SK_ID_CURR', 'TARGET']].to_csv('submission_grid_search.csv', index=False)\n",
    "    \n",
    "    # Nettoyage de la mémoire\n",
    "    del gsearch, X_train, y_train\n",
    "    gc.collect()\n",
    "\n",
    "    return gsearch.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca21a02-cab0-4daa-be6a-4db780aa925a",
   "metadata": {},
   "source": [
    "## Utiliser les fonctions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb143d4-36c7-4334-a546-0d7ac0b47783",
   "metadata": {},
   "source": [
    "remplaçer les blocs with timer() par des impressions directes, pour éviter l'erreur liée à l'utilisation de timer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "64b44eaf-2486-44ca-b412-5443b511a462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_bureau_and_balance(df, num_rows):\n",
    "    print(\"Processing bureau and bureau_balance\")\n",
    "    bureau = bureau_and_balance(num_rows)\n",
    "    print(\"Bureau df shape:\", bureau.shape)\n",
    "    df = df.join(bureau, how='left', on='SK_ID_CURR')\n",
    "    del bureau\n",
    "    gc.collect()\n",
    "    return df\n",
    "\n",
    "def process_previous_applications(df, num_rows):\n",
    "    print(\"Processing previous_applications\")\n",
    "    prev = previous_applications(num_rows)\n",
    "    print(\"Previous applications df shape:\", prev.shape)\n",
    "    df = df.join(prev, how='left', on='SK_ID_CURR')\n",
    "    del prev\n",
    "    gc.collect()\n",
    "    return df\n",
    "\n",
    "def process_POS_CASH_balance(df, num_rows):\n",
    "    print(\"Processing POS-CASH balance\")\n",
    "    pos = pos_cash(num_rows)\n",
    "    print(\"Pos-cash balance df shape:\", pos.shape)\n",
    "    df = df.join(pos, how='left', on='SK_ID_CURR')\n",
    "    del pos\n",
    "    gc.collect()\n",
    "    return df\n",
    "\n",
    "def process_installments_payments(df, num_rows):\n",
    "    print(\"Processing installments payments\")\n",
    "    ins = installments_payments(num_rows)\n",
    "    print(\"Installments payments df shape:\", ins.shape)\n",
    "    df = df.join(ins, how='left', on='SK_ID_CURR')\n",
    "    del ins\n",
    "    gc.collect()\n",
    "    return df\n",
    "    \n",
    "def process_credit_card_balance(df, num_rows):\n",
    "    print(\"Processing credit card balance\")\n",
    "    cc = credit_card_balance(num_rows)\n",
    "    print(\"Credit card balance df shape:\", cc.shape)\n",
    "    df = df.join(cc, how='left', on='SK_ID_CURR')\n",
    "    del cc\n",
    "    gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "225c5594-2e75-47a0-9449-396cf391db8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lightgbm(df, num_folds=10, stratified=False, debug=False):\n",
    "    print(\"Running LightGBM with kfold\")\n",
    "    feat_importance = kfold_lightgbm(df, num_folds=num_folds, stratified=stratified, debug=debug)\n",
    "    return feat_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd58361-53fc-4fc8-b526-b2e4daab18bc",
   "metadata": {},
   "source": [
    "## Traitement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3cc4b854-e378-4c38-8ee0-4678413a8f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(debug=False):\n",
    "    num_rows = 10000 if debug else None\n",
    "    df = application_train_test(num_rows)\n",
    "    \n",
    "    df = process_bureau_and_balance(df, num_rows)\n",
    "    df = process_previous_applications(df, num_rows)\n",
    "    df = process_installments_payments(df, num_rows)\n",
    "    df = process_credit_card_balance(df, num_rows)\n",
    "    df = process_POS_CASH_balance(df, num_rows)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9cdf4025-8a43-4d58-9d59-b08838cdb035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_process_data():\n",
    "    df = process_data()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6b1e25b0-4359-4bc1-a1e6-b8ae441e1604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 307511, test samples: 48744\n",
      "Processing bureau and bureau_balance\n",
      "Bureau df shape: (305811, 116)\n",
      "Processing previous_applications\n",
      "Previous applications df shape: (338857, 249)\n",
      "Processing installments payments\n",
      "Installments payments df shape: (339587, 26)\n",
      "Processing credit card balance\n",
      "Credit card balance df shape: (103558, 141)\n",
      "Processing POS-CASH balance\n",
      "Pos-cash balance df shape: (337252, 18)\n"
     ]
    }
   ],
   "source": [
    "# Call main_process_data() to process the data\n",
    "df = main_process_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4068106-9e42-4bdf-aaad-b5a4726cfbe4",
   "metadata": {},
   "source": [
    "## Le modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7699e483-8a7b-4966-832c-a30d8cf462c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LightGBM. Train shape: (307507, 797), test shape: (48744, 797)\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 80 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n80 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\naoue\\anaconda3\\envs\\mon_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\naoue\\anaconda3\\envs\\mon_env\\lib\\site-packages\\lightgbm\\sklearn.py\", line 1187, in fit\n    super().fit(\n  File \"C:\\Users\\naoue\\anaconda3\\envs\\mon_env\\lib\\site-packages\\lightgbm\\sklearn.py\", line 885, in fit\n    self._Booster = train(\n  File \"C:\\Users\\naoue\\anaconda3\\envs\\mon_env\\lib\\site-packages\\lightgbm\\engine.py\", line 255, in train\n    booster = Booster(params=params, train_set=train_set)\n  File \"C:\\Users\\naoue\\anaconda3\\envs\\mon_env\\lib\\site-packages\\lightgbm\\basic.py\", line 3433, in __init__\n    train_set.construct()\n  File \"C:\\Users\\naoue\\anaconda3\\envs\\mon_env\\lib\\site-packages\\lightgbm\\basic.py\", line 2462, in construct\n    self._lazy_init(data=self.data, label=self.label, reference=None,\n  File \"C:\\Users\\naoue\\anaconda3\\envs\\mon_env\\lib\\site-packages\\lightgbm\\basic.py\", line 2022, in _lazy_init\n    data, feature_name, categorical_feature, self.pandas_categorical = _data_from_pandas(\n  File \"C:\\Users\\naoue\\anaconda3\\envs\\mon_env\\lib\\site-packages\\lightgbm\\basic.py\", line 825, in _data_from_pandas\n    _pandas_to_numpy(data, target_dtype=target_dtype),\n  File \"C:\\Users\\naoue\\anaconda3\\envs\\mon_env\\lib\\site-packages\\lightgbm\\basic.py\", line 771, in _pandas_to_numpy\n    _check_for_bad_pandas_dtypes(data.dtypes)\n  File \"C:\\Users\\naoue\\anaconda3\\envs\\mon_env\\lib\\site-packages\\lightgbm\\basic.py\", line 763, in _check_for_bad_pandas_dtypes\n    raise ValueError('pandas dtypes must be int, float or bool.\\n'\nValueError: pandas dtypes must be int, float or bool.\nFields with bad pandas dtypes: CC_NAME_CONTRACT_STATUS_Active_MIN: object, CC_NAME_CONTRACT_STATUS_Active_MAX: object, CC_NAME_CONTRACT_STATUS_Approved_MIN: object, CC_NAME_CONTRACT_STATUS_Approved_MAX: object, CC_NAME_CONTRACT_STATUS_Completed_MIN: object, CC_NAME_CONTRACT_STATUS_Completed_MAX: object, CC_NAME_CONTRACT_STATUS_Demand_MIN: object, CC_NAME_CONTRACT_STATUS_Demand_MAX: object, CC_NAME_CONTRACT_STATUS_Refused_MIN: object, CC_NAME_CONTRACT_STATUS_Refused_MAX: object, CC_NAME_CONTRACT_STATUS_Sent proposal_MIN: object, CC_NAME_CONTRACT_STATUS_Sent proposal_MAX: object, CC_NAME_CONTRACT_STATUS_Signed_MIN: object, CC_NAME_CONTRACT_STATUS_Signed_MAX: object, CC_NAME_CONTRACT_STATUS_nan_MIN: object, CC_NAME_CONTRACT_STATUS_nan_MAX: object\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[104], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Vérifier si df n'est pas None avant de continuer\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Maintenant, df est prêt et peut être passé à la fonction du modèle\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     best_estimator \u001b[38;5;241m=\u001b[39m \u001b[43mkfold_lightgbm_grid_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_folds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstratified\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mErreur lors du traitement des données, df est None.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[91], line 45\u001b[0m, in \u001b[0;36mkfold_lightgbm_grid_search\u001b[1;34m(df, num_folds, stratified, debug)\u001b[0m\n\u001b[0;32m     42\u001b[0m y_train \u001b[38;5;241m=\u001b[39m train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTARGET\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Lancer la recherche par grille\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m \u001b[43mgsearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMeilleur score AUC: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m gsearch\u001b[38;5;241m.\u001b[39mbest_score_)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMeilleurs paramètres: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m gsearch\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mon_env\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mon_env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mon_env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1422\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mon_env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    870\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    873\u001b[0m     )\n\u001b[1;32m--> 875\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mon_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    408\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    409\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    412\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    413\u001b[0m     )\n\u001b[1;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    417\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    418\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    419\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    424\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 80 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n80 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\naoue\\anaconda3\\envs\\mon_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\naoue\\anaconda3\\envs\\mon_env\\lib\\site-packages\\lightgbm\\sklearn.py\", line 1187, in fit\n    super().fit(\n  File \"C:\\Users\\naoue\\anaconda3\\envs\\mon_env\\lib\\site-packages\\lightgbm\\sklearn.py\", line 885, in fit\n    self._Booster = train(\n  File \"C:\\Users\\naoue\\anaconda3\\envs\\mon_env\\lib\\site-packages\\lightgbm\\engine.py\", line 255, in train\n    booster = Booster(params=params, train_set=train_set)\n  File \"C:\\Users\\naoue\\anaconda3\\envs\\mon_env\\lib\\site-packages\\lightgbm\\basic.py\", line 3433, in __init__\n    train_set.construct()\n  File \"C:\\Users\\naoue\\anaconda3\\envs\\mon_env\\lib\\site-packages\\lightgbm\\basic.py\", line 2462, in construct\n    self._lazy_init(data=self.data, label=self.label, reference=None,\n  File \"C:\\Users\\naoue\\anaconda3\\envs\\mon_env\\lib\\site-packages\\lightgbm\\basic.py\", line 2022, in _lazy_init\n    data, feature_name, categorical_feature, self.pandas_categorical = _data_from_pandas(\n  File \"C:\\Users\\naoue\\anaconda3\\envs\\mon_env\\lib\\site-packages\\lightgbm\\basic.py\", line 825, in _data_from_pandas\n    _pandas_to_numpy(data, target_dtype=target_dtype),\n  File \"C:\\Users\\naoue\\anaconda3\\envs\\mon_env\\lib\\site-packages\\lightgbm\\basic.py\", line 771, in _pandas_to_numpy\n    _check_for_bad_pandas_dtypes(data.dtypes)\n  File \"C:\\Users\\naoue\\anaconda3\\envs\\mon_env\\lib\\site-packages\\lightgbm\\basic.py\", line 763, in _check_for_bad_pandas_dtypes\n    raise ValueError('pandas dtypes must be int, float or bool.\\n'\nValueError: pandas dtypes must be int, float or bool.\nFields with bad pandas dtypes: CC_NAME_CONTRACT_STATUS_Active_MIN: object, CC_NAME_CONTRACT_STATUS_Active_MAX: object, CC_NAME_CONTRACT_STATUS_Approved_MIN: object, CC_NAME_CONTRACT_STATUS_Approved_MAX: object, CC_NAME_CONTRACT_STATUS_Completed_MIN: object, CC_NAME_CONTRACT_STATUS_Completed_MAX: object, CC_NAME_CONTRACT_STATUS_Demand_MIN: object, CC_NAME_CONTRACT_STATUS_Demand_MAX: object, CC_NAME_CONTRACT_STATUS_Refused_MIN: object, CC_NAME_CONTRACT_STATUS_Refused_MAX: object, CC_NAME_CONTRACT_STATUS_Sent proposal_MIN: object, CC_NAME_CONTRACT_STATUS_Sent proposal_MAX: object, CC_NAME_CONTRACT_STATUS_Signed_MIN: object, CC_NAME_CONTRACT_STATUS_Signed_MAX: object, CC_NAME_CONTRACT_STATUS_nan_MIN: object, CC_NAME_CONTRACT_STATUS_nan_MAX: object\n"
     ]
    }
   ],
   "source": [
    "# Vérifier si df n'est pas None avant de continuer\n",
    "if df is not None:\n",
    "    # Maintenant, df est prêt et peut être passé à la fonction du modèle\n",
    "    best_estimator = kfold_lightgbm_grid_search(df, num_folds=5, stratified=False, debug=False)\n",
    "else:\n",
    "    print(\"Erreur lors du traitement des données, df est None.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "737da816-7cff-45d7-9973-19daa4ff39c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[101], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Assurez-vous que df est votre DataFrame final contenant à la fois les données d'entraînement et de test avec les nouvelles caractéristiques et encodages.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m best_estimator \u001b[38;5;241m=\u001b[39m \u001b[43mkfold_lightgbm_grid_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_folds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstratified\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[91], line 7\u001b[0m, in \u001b[0;36mkfold_lightgbm_grid_search\u001b[1;34m(df, num_folds, stratified, debug)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mkfold_lightgbm_grid_search\u001b[39m(df, num_folds, stratified\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Division en ensembles d'entraînement/validation et de test\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     train_df \u001b[38;5;241m=\u001b[39m df[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTARGET\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mnotnull()]\n\u001b[0;32m      8\u001b[0m     test_df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTARGET\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misnull()]\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting LightGBM. Train shape: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test shape: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(train_df\u001b[38;5;241m.\u001b[39mshape, test_df\u001b[38;5;241m.\u001b[39mshape))\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Assurez-vous que df est votre DataFrame final contenant à la fois les données d'entraînement et de test avec les nouvelles caractéristiques et encodages.\n",
    "best_estimator = kfold_lightgbm_grid_search(df, num_folds=5, stratified=False, debug=False)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f669c69-1bae-484b-9b15-c363ade8c219",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
